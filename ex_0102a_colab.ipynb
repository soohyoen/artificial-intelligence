{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ex_0102a_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soohyoen/artificial-intelligence/blob/main/ex_0102a_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ec833f"
      },
      "source": [
        "### 나이브 베이즈 분류기 - 트윗."
      ],
      "id": "a5ec833f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cebe945"
      },
      "source": [
        "**<span style=\"color:blue\">목표</span>**: 베이즈 정리를 적용하여 자연어 분류 모형을 만들어 본다."
      ],
      "id": "4cebe945"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82ef8a1d"
      },
      "source": [
        "<br>\n",
        "1. 베이즈 정리. <br>\n",
        "\n",
        " $P(A| W_1, W_2, W_3,...) = {P(W_1, W_2, W_3,...|A) \\cdot P(A) \\over P(W_1, W_2, W_3,....)}$ <br>\n",
        " $P(B| W_1, W_2, W_3,...) = {P(W_1, W_2, W_3,...|B) \\cdot P(B) \\over P(W_1, W_2, W_3,....)}$\n",
        "\n",
        "<br>\n",
        "2. 동일한 분모를 무시하면 다음 비례관계가 성립된다. <br>\n",
        "\n",
        " $P(A| W_1, W_2, W_3, \\ldots) \\sim P(W_1, W_2, W_3,...|A) \\cdot P(A) $ <br>\n",
        " $P(B| W_1, W_2, W_3, \\ldots) \\sim P(W_1, W_2, W_3,...|B) \\cdot P(B) $\n",
        " \n",
        "<br>\n",
        "3. 독립적인 단어 분포를 전제하면 다음과 같이 분해할 수 있다. <br>\n",
        "\n",
        " $P(A| W_1, W_2, W_3, \\ldots) \\sim  P(W_1|A)\\cdot P(W_2|A)\\cdot P(W_3|A) \\cdots P(A) $ <br>\n",
        " $P(B| W_1, W_2, W_3, \\ldots) \\sim P(W_1|B)\\cdot P(W_2|B)\\cdot P(W_3|B) \\cdots P(B) $\n",
        "\n",
        "<br>\n",
        "4. 이제는 로그함수를 적용해 본다. <br>\n",
        "\n",
        "$Log_A \\sim  Log(P(W_1|A)) +  Log(P(W_2|A)) + Log(P(W_3|A)) + \\ldots + Log(P(A)) $ <br>\n",
        "$Log_B \\sim  Log(P(W_1|B)) +  Log(P(W_2|B)) + Log(P(W_3|B)) + \\ldots + Log(P(B)) $\n",
        "<br>\n",
        "\n",
        "**<span style=\"color:blue\">결론</span>**:  $Log_A$와 $Log_B$를 비교해서 큰 쪽으로 인식!"
      ],
      "id": "82ef8a1d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "395f8367"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "id": "395f8367",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3170ba18"
      },
      "source": [
        "#### 1. 학습 자료를 읽어와서 전처리한다:"
      ],
      "id": "3170ba18"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3YCF3dwqCl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257e654e-2224-4bd2-f4a7-b4867163a3b8"
      },
      "source": [
        "# 구글 드라이브 마운트.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # 절차를 따라서 한다."
      ],
      "id": "a3YCF3dwqCl7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv1GUZO4qDeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df048da0-cc7c-4502-8cf2-4f815176f605"
      },
      "source": [
        "# 경로 이동.\n",
        "%cd \"/content/drive/MyDrive\""
      ],
      "id": "fv1GUZO4qDeo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a7c606f"
      },
      "source": [
        "# A 유형의 트윗을 읽어온다. \n",
        "f = open(\"/content/tweets_A.txt\",\"r\",encoding=\"ms949\")    # Encoding 주의!\n",
        "ta = f.readlines()\n",
        "f.close()\n",
        "\n",
        "# B 유형의 트윗을 읽어온다. \n",
        "f = open(\"/content/tweets_B.txt\",\"r\", encoding=\"ms949\")   # Encoding 주의!\n",
        "tb = f.readlines()\n",
        "f.close()"
      ],
      "id": "4a7c606f",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92a43ac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77da4cf9-c120-452c-d1db-9bd060bbba59"
      },
      "source": [
        "print(f\"A 유형의 수 : {len(ta)}\")\n",
        "print(f\"B 유형의 수 : {len(tb)}\")"
      ],
      "id": "92a43ac7",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A 유형의 수 : 150\n",
            "B 유형의 수 : 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68005f4c"
      },
      "source": [
        "# 전처리 해서 단어별 도수표를 만들어주는 함수.\n",
        "def preprocessor(tweets):\n",
        "    freq_dict = {}\n",
        "    for a_line in tweets:\n",
        "        a_line = a_line.lower()               # 소문자화.\n",
        "        a_line = re.sub(r\"\\W\",\" \",a_line)     # 특수문자 제거.\n",
        "        a_line = re.sub(r\"\\d\", \" \", a_line)   # 숫자 제거.\n",
        "        a_line = re.sub(\"a|the|and|or|because|at\", \" \",a_line)  #  불용어 제거.\n",
        "        a_line = a_line.split()               # 분절.\n",
        "        for a_word in a_line:\n",
        "            if len(a_word) > 3:               # 길이가 최소 조건을 충족하는 단어만 사용.\n",
        "                if a_word in freq_dict:\n",
        "                    freq_dict[a_word] += 1    # 카운트 누적.\n",
        "                else:\n",
        "                    freq_dict[a_word] = 2     # 처음 발견. 기본값 1 + 누적 1.\n",
        "    return freq_dict"
      ],
      "id": "68005f4c",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "436c4253"
      },
      "source": [
        "#### 2. 학습 모형을 준비해 둔다:"
      ],
      "id": "436c4253"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acb1bc2"
      },
      "source": [
        "# Series로 변환.\n",
        "freq_a = pd.Series(preprocessor(ta)).sort_values(ascending=False)\n",
        "freq_b = pd.Series(preprocessor(tb)).sort_values(ascending=False) "
      ],
      "id": "1acb1bc2",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78fcd1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bf167f-c6d6-4596-a2e7-689d1dd90fb5"
      },
      "source": [
        "# Vocabulary 사전 크기 확인.\n",
        "print(\"Size of A: {}\".format( len(freq_a)))\n",
        "print(\"Size of B: {}\".format( len(freq_b)))"
      ],
      "id": "78fcd1a6",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of A: 563\n",
            "Size of B: 624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08c8716f"
      },
      "source": [
        "# Vocabulary 수 맞춤.\n",
        "n_voca = 300\n",
        "freq_a = freq_a.iloc[:n_voca]\n",
        "freq_b = freq_b.iloc[:n_voca]"
      ],
      "id": "08c8716f",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93e0a3d0"
      },
      "source": [
        "# 로그 확률로 변환.\n",
        "freq_a_sum = freq_a.sum()\n",
        "freq_b_sum = freq_b.sum()\n",
        "log_prob_a = dict(np.log(freq_a/freq_a_sum))    # Log(P(W|A))\n",
        "log_prob_b = dict(np.log(freq_b/freq_b_sum))    # Log(P(W|B))"
      ],
      "id": "93e0a3d0",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "527354d9"
      },
      "source": [
        "#### 3. 테스트 데이터를 읽어온다:"
      ],
      "id": "527354d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4120713"
      },
      "source": [
        "# 테스트 트윗을 읽어온다 (X_test). \n",
        "f = open(\"/content/tweets_test.txt\",\"r\", encoding=\"ms949\")         # Encoding 주의!\n",
        "tt = f.readlines()\n",
        "f.close()\n",
        "\n",
        "# 테스트 트윗의 유형 정보를 읽어온다 (Y_test).\n",
        "f = open(\"/content/tweets_test_class.txt\",\"r\")\n",
        "Y_test_raw = f.read()                 # 한 덩어리로 읽어온다.\n",
        "Y_test = Y_test_raw.split()           # 분절을 통해서 깔끔히!\n",
        "f.close()"
      ],
      "id": "a4120713",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5536f16"
      },
      "source": [
        "#### 4. 예측을 실시한다:"
      ],
      "id": "f5536f16"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f65107"
      },
      "source": [
        "Y_pred = []\n",
        "for a_sentence in tt:\n",
        "    log_prob_sum_a = 0.\n",
        "    log_prob_sum_b = 0.\n",
        "    a_sent_preprocessed = preprocessor([a_sentence])\n",
        "    for a_word, a_freq in a_sent_preprocessed.items():\n",
        "        if a_word in log_prob_a:\n",
        "            log_prob_sum_a += log_prob_a[a_word]*a_freq\n",
        "        else:\n",
        "            log_prob_sum_a += np.log(1.0/freq_a_sum)*a_freq\n",
        "            \n",
        "        if a_word in log_prob_b:\n",
        "            log_prob_sum_b += log_prob_b[a_word]*a_freq\n",
        "        else:\n",
        "            log_prob_sum_b += np.log(1.0/freq_b_sum)*a_freq\n",
        "            \n",
        "    if (log_prob_sum_a > log_prob_sum_b):\n",
        "        Y_pred.append(\"A\")\n",
        "    else:\n",
        "        Y_pred.append(\"B\")"
      ],
      "id": "99f65107",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ad5b9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5fea07-16d3-4f1f-9e19-9f102fdac83a"
      },
      "source": [
        "# 정확도 계산.\n",
        "correct = pd.Series([ x == y for (x,y) in zip(Y_pred, Y_test) ])\n",
        "print(\"Accuracy : {}\".format(correct.mean()))"
      ],
      "id": "2ad5b9d7",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9f71adc"
      },
      "source": [
        ""
      ],
      "id": "e9f71adc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-kFQcOfp_0e"
      },
      "source": [
        ""
      ],
      "id": "S-kFQcOfp_0e",
      "execution_count": null,
      "outputs": []
    }
  ]
}