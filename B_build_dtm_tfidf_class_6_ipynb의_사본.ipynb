{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B_build_dtm_tfidf_class_6.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soohyoen/artificial-intelligence/blob/main/B_build_dtm_tfidf_class_6_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iUsnxOyHhD4",
        "outputId": "1b952be4-97ba-45f1-d79e-e497f9852a94"
      },
      "source": [
        "# install & import the libraries needed\n",
        "!pip3 install pandas\n",
        "!pip3 install scikit-learn\n",
        "from typing import List\n",
        "from math import log\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# for printing out all the columns of a pandas dataframe https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg4U3QY2IB_v"
      },
      "source": [
        "# The corpus\n",
        "CORPUS = [\n",
        "    'this is the first document',\n",
        "    'the first document is this',\n",
        "    'this is the second document',\n",
        "    'and this is the third document',\n",
        "    'is this the first document'\n",
        "]\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ2uAyiBIGbD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "e416938b-a51f-4790-8af4-818b426db554"
      },
      "source": [
        "# we will reuse the functions we completed in the previous tutorial\n",
        "def tf(term: str, doc: str) -> int:\n",
        "    # typing을 하는 이유: 오류를 미연에 방지하기 위해서 (단, IDE를 사용하는 경우에만)\n",
        "    # 더 정확한 버전 (is가 this에 포함 문제가 되므로)\n",
        "    tf = sum([\n",
        "      word == term     \n",
        "      for word in doc.split(\" \")  # word count\n",
        "    ])\n",
        "    return tf\n",
        "\n",
        "\n",
        "def build_dtm(corpus: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    we reuse what we implemented in previous tutorial\n",
        "    :param corpus:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # build vocabulary - use nested list comprehension, set, and list\n",
        "    words = [\n",
        "        word\n",
        "        for doc in corpus\n",
        "        for word in doc.split(\" \")\n",
        "    ]\n",
        "    vocab = list(set(words))\n",
        "\n",
        "    # populate dtm, ith a nested for loop\n",
        "    dtm = [\n",
        "           [tf(term, doc) for term in vocab]  # row\n",
        "           for doc in corpus\n",
        "    ]\n",
        "\n",
        "    # return dtm as a pandas dataframe\n",
        "    dtm = pd.DataFrame(data=dtm, columns=vocab)\n",
        "    return dtm\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-724cfb42993d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m     \u001b[0mwe\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mimplemented\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprevious\u001b[0m \u001b[0mtutorial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5888fENLIQqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "f61dc7a3-6485-4031-98fc-da3a0b817e4e"
      },
      "source": [
        "# complete this function\n",
        "def idf(term: str, corpus: List[str]) -> float:\n",
        "    ### TODO 1 ###\n",
        "    n = len(corpus)\n",
        "    df = sum([\n",
        "          term in doc.split(\" \") #True False\n",
        "          for doc in corpus\n",
        "    ])\n",
        "    idf = log(n / (1 + df))\n",
        "    # log(a/b) = loga - logb\n",
        "    # idf = log(n) - log(1 + df)\n",
        "    ##############\n",
        "    return idf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-36ff8176cb1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# complete this function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m### TODO 1 ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     df = sum([\n",
            "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ4-x2kMJsnl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "48df6f88-3b3a-4fd2-eb2e-be7cbcaf6c0f"
      },
      "source": [
        "def build_dtm_with_tfidf(corpus: List[str]) -> pd.DataFrame:\n",
        "    # access the columns with df.columns\n",
        "    # multiply idfs to each row with numpy's broadcast mul\n",
        "    dtm = build_dtm(corpus) # tf\n",
        "    ### TODO 2 ####\n",
        "    # reuse dtm to build dtm_tfidf\n",
        "    # use dtm.columns, idf, np.array(), dtm.to_numpy() and broadcast multiplication\n",
        "    idfs: List[float] = [\n",
        "          idf(term, corpus)               \n",
        "          for term in dtm.columns               \n",
        "    ]\n",
        "    # dunder methods __mul__\n",
        "    dtm_tfidf: np.ndarray = dtm.to_numpy() * np.array(idfs)  # 리스트, 혹은 넘파이 배열\n",
        "    ############### \n",
        "    return pd.DataFrame(data=dtm_tfidf, columns=dtm.columns)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e54e648ee10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dtm_with_tfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# access the columns with df.columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# multiply idfs to each row with numpy's broadcast mul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m### TODO 2 ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZPjM7MhomG-",
        "outputId": "8a9b7118-243a-4e13-b7e8-af68077c41b8"
      },
      "source": [
        "print(idf(\"the\", CORPUS))\n",
        "print(idf(\"second\", CORPUS))\n",
        "print(idf(\"eubin\", CORPUS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.1823215567939546\n",
            "0.9162907318741551\n",
            "1.6094379124341003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB_5uAIrKPqf",
        "outputId": "53b3657d-fafc-4685-aa31-e9ef350f33a6"
      },
      "source": [
        "# build dtm, and one with  \n",
        "dtm = build_dtm(CORPUS)\n",
        "dtm_tfidf = build_dtm_with_tfidf(CORPUS)\n",
        "print(dtm)\n",
        "print(dtm_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document  first  and  this  second  the  is  third\n",
            "0         1      1    0     1       0    1   1      0\n",
            "1         1      1    0     1       0    1   1      0\n",
            "2         1      0    0     1       1    1   1      0\n",
            "3         1      0    1     1       0    1   1      1\n",
            "4         1      1    0     1       0    1   1      0\n",
            "   document     first       and      this    second       the        is  \\\n",
            "0 -0.182322  0.223144  0.000000 -0.182322  0.000000 -0.182322 -0.182322   \n",
            "1 -0.182322  0.223144  0.000000 -0.182322  0.000000 -0.182322 -0.182322   \n",
            "2 -0.182322  0.000000  0.000000 -0.182322  0.916291 -0.182322 -0.182322   \n",
            "3 -0.182322  0.000000  0.916291 -0.182322  0.000000 -0.182322 -0.182322   \n",
            "4 -0.182322  0.223144  0.000000 -0.182322  0.000000 -0.182322 -0.182322   \n",
            "\n",
            "      third  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.000000  \n",
            "3  0.916291  \n",
            "4  0.000000  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oAQVQquMV2G"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다 (단어의 순서는 달라도 괜찮습니다):\n",
        "```\n",
        "   the  and  third  this  is  first  document  second\n",
        "0    1    0      0     1   2      1         1       0\n",
        "1    1    0      0     1   2      1         1       0\n",
        "2    1    0      0     1   2      0         1       1\n",
        "3    1    1      1     1   2      0         1       0\n",
        "4    1    0      0     1   2      1         1       0\n",
        "        the       and     third      this        is     first  document  \\\n",
        "0 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "1 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "2 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.000000 -0.182322   \n",
        "3 -0.182322  0.916291  0.916291 -0.182322 -0.364643  0.000000 -0.182322   \n",
        "4 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "\n",
        "     second  \n",
        "0  0.000000  \n",
        "1  0.000000  \n",
        "2  0.916291  \n",
        "3  0.000000  \n",
        "4  0.000000  \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSEEqll0Kp--"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SsHSXRkKTLK",
        "outputId": "e06d34d0-0f22-4610-85e2-aecf1c2ef0f8"
      },
      "source": [
        "# compare the two\n",
        "print(cosine_similarity(dtm.to_numpy(), dtm.to_numpy()))\n",
        "print(cosine_similarity(dtm_tfidf.to_numpy(), dtm_tfidf.to_numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         1.         0.8        0.73029674 1.        ]\n",
            " [1.         1.         0.8        0.73029674 1.        ]\n",
            " [0.8        0.8        1.         0.73029674 0.8       ]\n",
            " [0.73029674 0.73029674 0.73029674 1.         0.73029674]\n",
            " [1.         1.         0.8        0.73029674 1.        ]]\n",
            "[[1.         1.         0.31538537 0.23104796 1.        ]\n",
            " [1.         1.         0.31538537 0.23104796 1.        ]\n",
            " [0.31538537 0.31538537 1.         0.10015744 0.31538537]\n",
            " [0.23104796 0.23104796 0.10015744 1.         0.23104796]\n",
            " [1.         1.         0.31538537 0.23104796 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzdJrp3mMfPg"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다:\n",
        "```\n",
        "[[1.         1.         0.8        0.73029674 1.        ]\n",
        " [1.         1.         0.8        0.73029674 1.        ]\n",
        " [0.8        0.8        1.         0.73029674 0.8       ]\n",
        " [0.73029674 0.73029674 0.73029674 1.         0.73029674]\n",
        " [1.         1.         0.8        0.73029674 1.        ]]\n",
        "[[1.         1.         0.31538537 0.23104796 1.        ]\n",
        " [1.         1.         0.31538537 0.23104796 1.        ]\n",
        " [0.31538537 0.31538537 1.         0.10015744 0.31538537]\n",
        " [0.23104796 0.23104796 0.10015744 1.         0.23104796]\n",
        " [1.         1.         0.31538537 0.23104796 1.        ]]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg2616UaMrg6"
      },
      "source": [
        "## 다음의 질문에 답해주세요!\n",
        "\n",
        "> `dtm`으로 구한 유사도 행렬 대비, `dtm_tfidf`로 구한 유사도 행렬은 어떤 점이 개선되었나요? 그 이유는?\n",
        "\n",
        "개선된 점:\n",
        "유사도 행렬이 좀 더 정확해졌다. 다른 의미인 문장들의 유사도는 내려간다.\n",
        "- 홍예은09:16\n",
        "유사도 행렬의 값들이 다양해집니다\n",
        "- 박민우09:17\n",
        "값 사이의 차이가 커져서 분리하기 쉽다\n",
        " \n",
        "이유:\n",
        "-  홍예은09:14\n",
        "단순 개수가 아닌 상대적 빈도를 계산하기 때문에 불용어의 중요도가 낮아집니다. 문서를 대변할만한 단어의 중요도가 올라간다.\n",
        "- 박민우09:15\n",
        "불용어가 문장의 keyword가 되는 것을 방지합니다\n",
        "- 박재운09:16\n",
        "각 단어의 중요한 값의 가중치를 부여하여 중요한 단어를 잘 표현할 수 있음\n",
        "\n",
        "IDF(t) = log(n) / 1 + DF(t) 수식 에서 (n) 값이랑 DF(t) 값이 차이가 1이면 분자랑 분모가 같아져서 값이 0이 나옵니다.\n",
        "\n",
        "\n",
        "> `dtm_tfidf`로도 해결할수 없는 문제를 발견할 수 있나요?\n",
        "\n",
        "- 홍예은09:19\n",
        "1. 여전히 어순을 인지하지 못한다. ('this is the first document' == 'is this the first document')\n",
        "2. 드물게 나타나지만 문서를 구성하는 요소 또한 키워드로 인식한다. (e.g. 'and', 'of' ...)\n",
        "3. 단어의 변형을 인지하지 못하므로 (e.g. document, documents) 전처리에 영향을 크게 받는다. \n",
        "4. 키워드 판별 척도가 빈도이므로 동음이의어, 다의어, 단어의 개념적 유사도(e.g. 한국, 대한민국)를 고려하지 못한다.\n",
        "5. 중요한 단어도 말뭉치 안에서 자주 사용될 수 있다. (전제의 오류)\n",
        "\n",
        "\n",
        "- 박민우09:20\n",
        "문장 어순을 인지할 수 없음. **합성어와 그를 이루는 단어가 함께 나올 경우**,  keyword를 잘못 결정하는 상황이 발생할 수 있음\n",
        "\n",
        "e.g. -> after rain, The rain + bow appeared.\n",
        "subword tokenization (필요한 이유)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiUb1sg1sEUK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEGqECWqKo50"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}